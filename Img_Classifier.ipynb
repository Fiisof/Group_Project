{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_M47oZUfDT4u"
      },
      "source": [
        "**Make sure your compute resource is set to GPU else you'll need to reset your session from scratch**\n",
        "\n",
        "---\n",
        "Group yourself to 3 max, and fill in below details\n",
        "Group member detail(s): \\\n",
        "1. Awang Amir Zakwan bin Awang Mahmud - 21B6013\n",
        "2. Azeema Nasrin Bazrul Jama - 22B2032\n",
        "3. Muhamad Sufi bin Sofri - 21B2114\n",
        "\n",
        "Some of the concepts may be technically advanced, instead, it is to focus on learning how to effectively use Google Colab for scientific research. Don't fret if you dont understand any of codes written for you."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Xprg08vEQqD"
      },
      "source": [
        "# Setting up Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAOS-EJzEavg"
      },
      "source": [
        "Task 1: Set Up the Environment \\\n",
        "Import the necessary libraries for the exercise, PyTorch for neural network training.\\\n",
        "Load the CIFAR10 dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1qZrtDipATDh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from google.colab import files\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "J23xkfU4AVpC"
      },
      "outputs": [],
      "source": [
        "# Set the device to GPU if available, otherwise, use CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "u1bdybnT-Z1j"
      },
      "outputs": [],
      "source": [
        "# Define the modified neural network architecture for CIFAR-10\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(8 * 8 * 32, 128)  # Adjusted for CIFAR-10 image size\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, 10)  # Output size matches the number of CIFAR-10 classes (10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.pool2(x)\n",
        "        x = x.view(-1, 8 * 8 * 32)  # Adjusted for CIFAR-10 image size\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KACp73JDFg57"
      },
      "source": [
        "Below are the Hyperparameters for the neural network (think of it as knobs that you can tune to enhance performance)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmsOBQ1kXFHA"
      },
      "source": [
        "Task 4: Model debugging (Mess around with these 3 hyperparameters) \\\n",
        "hint: \\\n",
        "LEARNING_RATE: The current value is set to 1e10 (10000000000.0). Try adjusting it to find an optimal learning rate.\\\n",
        "BATCH_SIZE: Set it to a power of 2, such as 16, 32, or 64, to potentially improve training efficiency. \\\n",
        "EPOCH: Consider letting the model train for more epochs. The default value is set to 1; experiment with longer training durations for better convergence and performance evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NDlnlmgKFhiK"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 2\n",
        "LEARNING_RATE = 1e12\n",
        "EPOCH = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "G5q7aHCZAZWw"
      },
      "outputs": [],
      "source": [
        "# Function to train the model\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs=5):\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        correct_predictions = 0  # Initialize a counter for correct predictions\n",
        "        total_samples = 0  # Initialize a counter for total samples\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "             # Measure accuracy\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "        # Calculate accuracy for the current epoch\n",
        "        accuracy = 100.0 * correct_predictions / total_samples\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}, Accuracy: {accuracy}\")\n",
        "    print(\"Training complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k59nYWhsB1n0",
        "outputId": "92286400-9e95-421f-abb8-ca9f54554100"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:09<00:00, 18905897.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ],
      "source": [
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnSb5bBsAakx",
        "outputId": "1c43e11b-e9f5-4839-825a-3a8d1e0f1a72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess the CFAR10 dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "#TODO: Complete below line to import CIFAR10 dataset\n",
        "train_set = torchvision.datasets.CIFAR10(root='./data/', train=True,download=True, transform=transform)\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9uu5lfFF-FH",
        "outputId": "8f44a803-8684-477a-d5c0-e5ca97830185"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['airplane',\n",
              " 'automobile',\n",
              " 'bird',\n",
              " 'cat',\n",
              " 'deer',\n",
              " 'dog',\n",
              " 'frog',\n",
              " 'horse',\n",
              " 'ship',\n",
              " 'truck']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "trainset.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EUYLg9WRAdUp"
      },
      "outputs": [],
      "source": [
        "# Create the model, loss function, and optimizer\n",
        "model = SimpleCNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8Yh4J-wUR1W"
      },
      "source": [
        "Task 2: Measure performance difference training between GPU and CPU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teF6NB2dAeV-",
        "outputId": "0625e245-f6b7-473a-aa89-30927347be9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: nan, Accuracy: 10.0\n",
            "Epoch 2/5, Loss: nan, Accuracy: 10.0\n",
            "Epoch 3/5, Loss: nan, Accuracy: 10.0\n",
            "Epoch 4/5, Loss: nan, Accuracy: 10.0\n",
            "Epoch 5/5, Loss: nan, Accuracy: 10.0\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "train_model(model, train_loader, criterion, optimizer, num_epochs=EPOCH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyN4gk65UUAl"
      },
      "source": [
        "Report your findings on:\n",
        "*   What were the key differences you observed in the training speed between the GPU and CPU?\n",
        "*   Were there any challenges or limitations you encountered while using the GPU for training?\n",
        "*   Did you notice any impact on the final model's performance (accuracy, loss) when trained on the GPU versus the CPU?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsInMplEVyCK"
      },
      "source": [
        "Task 3: Visualize Loss and Accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGiiegGeVYEn"
      },
      "outputs": [],
      "source": [
        "#TODO:\n",
        "#Your plots goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUNYsuwRX-VT"
      },
      "source": [
        "Task 4: Test your own Image \\\n",
        "You can use the same code from the tutorial and ensure your model is properly trained!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "LN02H0eTYC68"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((28, 28)),  # Resize the image to match the model input size\n",
        "    transforms.ToTensor(),  # Convert the image to a tensor\n",
        "   transforms.Normalize((0.5,), (0.5,)),  # Normalize the image\n",
        "])\n",
        "\n",
        "# Function to preprocess and make predictions on the uploaded image\n",
        "def predict_uploaded_image(upload):\n",
        "    # Open the uploaded image\n",
        "    image = Image.open(upload).convert('L')\n",
        "    model.to(\"cpu\")  # Set the model to evaluation mode\n",
        "\n",
        "    # Preprocess the image\n",
        "    input_tensor = transform(image)\n",
        "    input_batch = input_tensor.unsqueeze(0)  # Add a batch dimension\n",
        "\n",
        "    # Make predictions using the model\n",
        "    with torch.no_grad():\n",
        "        output = model(input_batch)\n",
        "    _, predicted_idx = torch.max(output, 1)\n",
        "\n",
        "    print(f\"Predicted labels: {predicted_idx}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload an image for prediction\n",
        "uploaded = files.upload()\n",
        "\n",
        "# If an image is uploaded, call the prediction function\n",
        "if len(uploaded) > 0:\n",
        "    for file_name in uploaded.keys():\n",
        "        predict_uploaded_image(file_name)\n",
        "else:\n",
        "    print(\"No image uploaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "feYbXgGVgndU",
        "outputId": "e85e2b8b-cd57-4444-a368-e9ecf7c3b663"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-db526fc1-1555-44bf-a596-8bea9fc864fc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-db526fc1-1555-44bf-a596-8bea9fc864fc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No image uploaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ST-Jo3Cdgqz0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}